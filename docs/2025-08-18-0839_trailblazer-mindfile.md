# Trailblazer Mindfile — Run/DB Recovery, Embedding, and Retrieval QA

**Timestamp (ET):** 2025-08-18T08:39:37.139182-04:00
**Repo:** `miket-llc/n2s-trailblazer`\
**Scope:** Preserve institutional memory so a fresh chat can pick up immediately.

______________________________________________________________________

## What Trailblazer Is (one-liner)

**Trailblazer** is an AI-powered knowledge-base builder for Ellucian. It ingests Ellucian Confluence (ADF) and Oxygen Content Fusion (DITA/XML), **normalizes → enriches → chunks → embeds** into **Postgres+pgvector**, and supports retrieval/ask workflows with strict **traceability back to sources & media**.

______________________________________________________________________

## Canonical Pipeline (current agreement)

1. **Ingest** (Confluence ADF; DITA XML) → `var/runs/<RID>/ingest/`
1. **Normalize** → canonical doc records (`normalized.ndjson`)
1. **Enrich** → rule-based (+ optional LLM) signals and **fingerprints** (`enriched.jsonl`)
1. **Chunk** (materialize) → writes `var/runs/<RID>/chunk/chunks.ndjson` + `chunk_assurance.json`
1. **Embed** → gated by `trailblazer embed preflight`; writes `embed_assurance.json`
1. **Retrieve & Pack** → dense (pgvector), deterministic tie-breakers, budget-aware packer
1. **Ask** → artifacts (hits/context/summary) with traceability

> **Postgres only** for ops. **No SQLite** fallback in production. SQLite may be used only in unit tests behind `TB_TESTING=1`.

______________________________________________________________________

## Directory Conventions (unified under `var/`)

- `var/runs/<RID>/normalize/normalized.ndjson` — normalized docs per run
- `var/runs/<RID>/enrich/enriched.jsonl` — enrichment signals & fingerprints
- `var/runs/<RID>/chunk/chunks.ndjson` — materialized chunks with token counts
- `var/runs/<RID>/chunk/chunk_assurance.json` — chunk quality metrics and validation
- `var/runs/<RID>/preflight/preflight.json` — preflight validation results and stats
- `var/runs/<RID>/embed/embed_assurance.json` — per-run embed metrics (references chunk assurance)
- `var/logs/` — embedding/ask logs; monitored, archived (no deletion without archive)
- `var/backups/` — **pg_dump** artifacts (`schema.sql`, `embeddings.dump`, `manifest.json`)
- `var/progress/embedding.json` — progress tracker (if present)
- `var/temp_runs_to_embed.txt` — plan generated by re-embed scripts

______________________________________________________________________

## Non-Negotiables (Shared Guardrails — keep in `prompts/000_shared_guardrails.md`)

- **One DB only:** Postgres (+pgvector) in ops. No SQLite fallbacks.
- **Destructive ops require explicit ack** (e.g., `DB_RESET_ALLOWED=YES`). Never touch `var/`.
- **No pagers:** `PAGER=cat`, `LESS=-RFX`, `GIT_PAGER=cat`; avoid commands that page output.
- **Zsh-safe quoting:** prefer single quotes; avoid nested quotes in tmux.
- **Zero linter/test failures:** `make fmt && make lint && make test && make check-md` must be green.
- **Deterministic retrieval:** order by **score DESC**, tie-break by **(doc_id ASC, chunk_id ASC)**.
- **Traceability:** keep `title`, `url`, `source_system`, `space_id/key`, `labels`, and **media placeholders/links** in chunks and packed context.
- **Backups first:** Never modify/drop embeddings without a same-day backup in `var/backups/`.

______________________________________________________________________

## Current Status & Recent Events (why this mindfile exists)

- We **previously embedded the full corpus**, but a recent mishap **wiped the DB**, leaving ~**286 docs**.
- We retained all artifacts under **`var/`** (normalize/enrich), so we can **rebuild DB state** without re-ingesting.
- Issues encountered & fixed patterns:
  - **Dummy vs OpenAI provider:** Ensure env vars are set **inside tmux**; otherwise workers may default incorrectly.
  - **Pager triggers:** Use `PAGER=cat`, `LESS=-RFX`, and `psql -P pager=off` everywhere.
  - **Quoting in zsh/Cursor:** Avoid nested quoted commands; with tmux use `tmux setenv` + `tmux send-keys`.
  - **Observability:** use assurance files, monitor script (EWMA/ETA), and clear console output.
- Model choice: **OpenAI `text-embedding-3-small` (1536 dimension)** for cost/quality balance. (Allowed alternates: `text-embedding-3-large` or a vetted local model—requires end-to-end rework).

______________________________________________________________________

## Canonical Reset & Re-Embed (from `var/` only) — High-Level

> Use this *only* when DB is bad. It **does not** touch `var/` artifacts.

1. **Stop workers:** kill tmux `embed_workers`, kill stray embed procs.
1. **Reset DB:** `docker compose -f docker-compose.db.yml down -v && up -d` → `trailblazer db init && db doctor`
1. **Verify enrichment exists:** ensure `var/runs/*/enrich/enriched.jsonl` lines > 0.
1. **Build plan:** `reembed_corpus_openai.sh --list-only` → `var/temp_runs_to_embed.txt` (largest first).
1. **Plan-preflight:** run `trailblazer embed plan-preflight --provider openai --model text-embedding-3-small --dimension 1536`
1. **Dispatch with ready.txt:** use `var/plan_preflight/<TS>/ready.txt`; archive the plan-preflight folder alongside dispatch logs.
1. **Monitor:** `monitor_embedding.sh` → expect rising docs/chunks, **active_workers**, **EWMA rate**, stable **ETA**.
1. **Verify:** `SELECT provider, dimension, COUNT(*) FROM chunk_embeddings GROUP BY 1,2;` → expect 1 row `(openai, 1536, N)` and `trailblazer ask "<N2S query>"` smoke tests.

______________________________________________________________________

## Retrieval QA (domain-focused)

Use **real Ellucian/N2S queries** (not app internals):

- “What are the stages of the Navigate to SaaS methodology?”
- “How does Sprint 0 differ from Prepare?”
- “Show me documentation about Banner integrations during SaaS migrations.”
- “What are the responsibilities of a Solution Architect in N2S projects?”
- “Find runbooks related to Curriculum Management.”

Artifacts: `var/retrieval_qc/ask_*.json`, packed contexts at 1500/4000/6000 chars, `readiness.json` with counts, timings, anomalies.

______________________________________________________________________

## Scripts & CLI (keep minimal surface area)

- **Keep (or align) only what’s necessary:**
  - `scripts/reembed_corpus_openai.sh` — plan + run orchestration (list-only, serial, logs, progress).
  - `scripts/embed_dispatch.sh` — simple multi-worker dispatcher (reads plan).
  - `scripts/monitor_embedding.sh` — worker-aware ETA (EWMA) and progress display.
  - `scripts/kill_embedding.sh` — idempotent cleanup.
- **Prefer CLI for logic**; scripts should orchestrate only.
- Ensure any script sets: `set -euo pipefail`, `PAGER=cat`, `LESS=-RFX`, and is zsh-safe.

______________________________________________________________________

## Backups (required before any risky change)

- `scripts/backup_pg_embeddings.sh` → `var/backups/<TS>/` containing:
  - `schema.sql` (schema-only), `embeddings.dump` (custom format), `manifest.json`
- Restore procedure is documented but **never auto-run**.

______________________________________________________________________

## Known Pitfalls / How We Avoid Them

- **Env leakage into tmux** → fix by `tmux setenv -g VAR value` for all embed vars (provider/model/dimension/batch/workers).
- **Pager blocking output** → fix by `PAGER=cat`, `LESS=-RFX`, `psql -P pager=off -X`.
- **Skipping work silently** → ensure `--reembed-all` as needed; check `embed_assurance.json` per run.
- **Zero-work embeds (no chunks)** → always run preflight; fail fast.
- **SQLite reappearing** → forbid in ops; gate unit tests with `TB_TESTING=1`.
- **Confusing logs** → consolidate under `var/logs/`, archive old runs in `var/logs/_archive/<TS>/` (don't delete blindly).

______________________________________________________________________

## Immediate Next Steps

1. If DB is good: **Retrieval QA** with domain queries; generate `var/retrieval_qc/*` artifacts; fix any anomalies surgically.
1. If DB was wiped/dirty: run the **Reset & Re-Embed** flow above (pilot → dispatch → monitor → verify).
1. Once retrieval passes QA: move to **Composer/Creator** templates and end-to-end “ask” deliverables.

______________________________________________________________________

## One-Glance Checklist (for a fresh operator)

- [ ] Postgres up, `db doctor` OK (pgvector).
- [ ] Enriched runs present & non-empty.
- [ ] Plan built: `var/temp_runs_to_embed.txt`.
- [ ] Preflight passed; plan-preflight bundle present; assurance files present.
- [ ] Pilot succeeded (openai, 1536, docs/chunks > 0).
- [ ] Dispatcher running in tmux with env set via `tmux setenv`.
- [ ] Monitor shows progress + ETA.
- [ ] Retrieval smoke test returns N2S-domain results with traceable metadata.
- [ ] Backups taken for embeddings before any risky change.

______________________________________________________________________

*Paste this mindfile into your new chat and we can instantly pick up the thread with full context.*
